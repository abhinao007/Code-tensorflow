{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Long Short-term Memory for Text Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses LSTM neural network to generate text from Nietzsche's writings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "from tensorflow.keras.utils import get_file\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the data\n",
    "Nietzsche's writing dataset is available online. The following code download the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/nietzsche.txt\n",
      "606208/600901 [==============================] - 0s 1us/step\n"
     ]
    }
   ],
   "source": [
    "path = get_file(\n",
    "    'nietzsche.txt',\n",
    "    origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "with io.open(path, encoding='utf-8') as f:\n",
    "    text = f.read().lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 600893\n"
     ]
    }
   ],
   "source": [
    "print('corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "supposing that truth is a woman--what then? is there not ground\n",
      "for suspecting that all philosophers, in so far as they have been\n",
      "dogmatists, have failed to understand women--that the terrible\n",
      "seriousness and clumsy importunity with which they have usually paid\n",
      "their addresses to truth, have been unskilled and unseemly methods for\n",
      "winning a woman? certainly she has never allowed herself to be won; and\n",
      "at present every kind of dogma stands with sad and discouraged mien--if,\n",
      "indeed, it stands at all!\n"
     ]
    }
   ],
   "source": [
    "print(text[10:513])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 57\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "# total nomber of characters\n",
    "print('total chars:', len(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean data\n",
    "\n",
    "We cut the text in sequences of maxlen characters with a jump size of 3.\n",
    "The features for each example is a matrix of size maxlen*num of chars.\n",
    "The label for each example is a vector of size num of chars, which represents the next character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create (character, index) and (index, character) dictionary\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 200285\n"
     ]
    }
   ],
   "source": [
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "print('Vectorization...')\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(layers.Dense(len(chars), activation='softmax'))\n",
    "\n",
    "optimizer = optimizers.RMSprop(learning_rate=0.001, decay=1e-5)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the model\n",
    "\n",
    "Use the `.summary` method to print a simple description of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 128)               95232     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 57)                7353      \n",
      "=================================================================\n",
      "Total params: 102,585\n",
      "Trainable params: 102,585\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PrintLoss(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, _):\n",
    "        # Function invoked at end of each epoch. Prints generated text.\n",
    "        print()\n",
    "        print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "        start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "        for diversity in [0.5, 1.0]:\n",
    "            print('----- diversity:', diversity)\n",
    "\n",
    "            generated = ''\n",
    "            sentence = text[start_index: start_index + maxlen]\n",
    "            generated += sentence\n",
    "            print('----- Generating with seed: \"' + sentence + '\"')\n",
    "            sys.stdout.write(generated)\n",
    "\n",
    "            for i in range(400):\n",
    "                x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "                for t, char in enumerate(sentence):\n",
    "                    x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "                preds = model.predict(x_pred, verbose=0)[0]\n",
    "                next_index = sample(preds, diversity)\n",
    "                next_char = indices_char[next_index]\n",
    "\n",
    "                sentence = sentence[1:] + next_char\n",
    "\n",
    "                sys.stdout.write(next_char)\n",
    "                sys.stdout.flush()\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "1252/1252 [==============================] - 41s 32ms/step - loss: 2.5603 - accuracy: 0.2777 - val_loss: 2.2750 - val_accuracy: 0.3440\n",
      "\n",
      "----- Generating text after Epoch: 0\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" habit at present of taking the side of \"\n",
      " habit at present of taking the side of whan the erating of the there sos to\n",
      "ceresite be the dreinco the the her and an the is of mertitt the ses ias at the nand of the fore to the the wire is and ther furu ser and in the ion if on the tore sthe wher and rat of ar the terithe\n",
      "n the thacof as tereseling and and and fomen the the the fore fere of the mintithe\n",
      "\n",
      "him ti the mariting in ave sorel, fo the there in the rofere to ther whe the th\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \" habit at present of taking the side of \"\n",
      " habit at present of taking the side of tes ach\n",
      "cereanife ung, of rsofidiniented tilr for fecue afs, foro tas malg evertalviwed tof ibley po ferant-celftitldes psdee a donte as fund nat ind bongit. w uf tor panewise hane\n",
      "aon is inte nocedendipw and. it touily ass tiald, plemas \"cliingofcat the woncg sreding  ff\n",
      "22ith, pealep_!erureon hfid if co ther ins witol\n",
      "iss of efr inghiwne sherterf, whil, the ore mail to th hh thin at on caenrisou\n",
      "Epoch 2/60\n",
      "1252/1252 [==============================] - 43s 34ms/step - loss: 2.1965 - accuracy: 0.3620 - val_loss: 2.0933 - val_accuracy: 0.3904\n",
      "\n",
      "----- Generating text after Epoch: 1\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" the joke of this gloomy grimace and tur\"\n",
      " the joke of this gloomy grimace and ture thead reatser and a that efrerad of andore the mentist, the montering of that is the severy as which it on the phistity.\n",
      "\n",
      "22.. all and oment and where the stind deveritas of mand in the the poprition of in mare the that on at in his mestity is of that there the sopher the somporited the the the deverse and of the comperenon in the montirations of the hesmens and the sare the sither of that in th\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \" the joke of this gloomy grimace and tur\"\n",
      " the joke of this gloomy grimace and turente star haisthang\n",
      "on amstsewtototlamady why huse somstad in a the decprion semmicatidg, alf it te thald irntelvenly to sustirl, ass ale of \"phly ohar inter\"\n",
      "it hius enen; o which, if to eosthas uist merthordve delem ald whats ol -angand.-weist uals, whace ; tha in to\n",
      "lang and in sher sicgulte--of they ceny aro-tamnaesty ink. oxedut edo; wuvo hone the the sorlity ora\n",
      "wh owe one\"un\"ls of they is a\n",
      "Epoch 3/60\n",
      "1252/1252 [==============================] - 44s 35ms/step - loss: 2.0421 - accuracy: 0.4032 - val_loss: 1.9857 - val_accuracy: 0.4167\n",
      "\n",
      "----- Generating text after Epoch: 2\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"nt--it was thus,\n",
      "for example, that the g\"\n",
      "nt--it was thus,\n",
      "for example, that the geraning of enceatal and him sould not which to the reations and the verse to deent has the thar a sould be wha ha for he prestanes so proise the philosopher it of the disturarity and an is couls and the berasting it of the and and whill be for not word who gent the self and the salf the bean stand the hast in the santer and and suntorate it to the sight of the were the with what an sund and and wh\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"nt--it was thus,\n",
      "for example, that the g\"\n",
      "nt--it was thus,\n",
      "for example, that the gand, ano\n",
      "augs teal daund des mustrunce ou st, phichsespch apporabties--of the ansentong . ow tho urpease of preanes by list pruis co polioly til, mymatifgrat of thak to carented \"wh he hear tounty it leed the the vost'our is alversy of\n",
      "gomper, and descemtitiwepr\n",
      "reymanaricion, of \n",
      "he mounothit\n",
      "un insightscod ubd to perin with have ond mond,atha in han net is fou peraul sunt be dastity, hzatilis of\n",
      "Epoch 4/60\n",
      "1037/1252 [=======================>......] - ETA: 6s - loss: 1.9395 - accuracy: 0.4300"
     ]
    }
   ],
   "source": [
    "EPOCHS = 60\n",
    "BATCH = 128\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "history = model.fit(x, y,\n",
    "                    batch_size = BATCH,\n",
    "                    epochs = EPOCHS,\n",
    "                    validation_split = 0.2,\n",
    "                    verbose = 1,\n",
    "                    callbacks = [early_stop, PrintLoss()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
